{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook for testing purposes\n",
    "\n",
    "##### Imports and global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser  # for reading the parameters file\n",
    "import sys  # for system errors and printouts\n",
    "from pathlib import Path  # for paths of files\n",
    "import os  # for reading the input data\n",
    "import time  # for timing\n",
    "import pandas as pd\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "parameter_file = 'default_parameters.ini'  # the main parameters file\n",
    "# the main path where all the data directories are\n",
    "data_main_directory = Path('data')\n",
    "# dictionary that holds the input parameters, key = parameter name, value = value\n",
    "parameters_dictionary = dict()\n",
    "# dictionary of the input documents, key = document id, value = the document\n",
    "document_list = dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-implemented methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DO NOT CHANGE THIS METHOD\n",
    "# Reads the parameters of the project from the parameter file 'file'\n",
    "# and stores them to the parameter dictionary 'parameters_dictionary'\n",
    "def read_parameters():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(parameter_file)\n",
    "    for section in config.sections():\n",
    "        for key in config[section]:\n",
    "            if key == 'data':\n",
    "                parameters_dictionary[key] = config[section][key]\n",
    "            elif key == 'naive':\n",
    "                parameters_dictionary[key] = bool(config[section][key])\n",
    "            elif key == 't':\n",
    "                parameters_dictionary[key] = float(config[section][key])\n",
    "            else:\n",
    "                parameters_dictionary[key] = int(config[section][key])\n",
    "\n",
    "\n",
    "# DO NOT CHANGE THIS METHOD\n",
    "# Reads all the documents in the 'data_path' and stores them in the dictionary 'document_list'\n",
    "def read_data(data_path):\n",
    "    for (root, dirs, file) in os.walk(data_path):\n",
    "        for f in file:\n",
    "            file_path = data_path / f\n",
    "            doc = open(file_path).read().strip().replace('\\n', ' ')\n",
    "            file_id = int(file_path.stem)\n",
    "            document_list[file_id] = doc\n",
    "\n",
    "\n",
    "# DO NOT CHANGE THIS METHOD\n",
    "# Calculates the Jaccard Similarity between two documents represented as sets\n",
    "def jaccard(doc1, doc2):\n",
    "    return len(doc1.intersection(doc2)) / float(len(doc1.union(doc2)))\n",
    "\n",
    "\n",
    "# DO NOT CHANGE THIS METHOD\n",
    "# Define a function to map a 2D matrix coordinate into a 1D index.\n",
    "def get_triangle_index(i, j, length):\n",
    "    if i == j:  # that's an error.\n",
    "        sys.stderr.write(\"Can't access triangle matrix with i == j\")\n",
    "        sys.exit(1)\n",
    "    if j < i:  # just swap the values.\n",
    "        temp = i\n",
    "        i = j\n",
    "        j = temp\n",
    "\n",
    "    # Calculate the index within the triangular array. Taken from pg. 211 of:\n",
    "    # http://infolab.stanford.edu/~ullman/mmds/ch6.pdf\n",
    "    # adapted for a 0-based index.\n",
    "    k = int(i * (length - (i + 1) / 2.0) + j - i) - 1\n",
    "\n",
    "    return k\n",
    "\n",
    "\n",
    "# DO NOT CHANGE THIS METHOD\n",
    "# Calculates the similarities of all the combinations of documents and returns the similarity triangular matrix\n",
    "def naive():\n",
    "    docs_Sets = []  # holds the set of words of each document\n",
    "\n",
    "    for doc in document_list.values():\n",
    "        docs_Sets.append(set(doc.split()))\n",
    "\n",
    "    # Using triangular array to store the similarities, avoiding half size and similarities of i==j\n",
    "    num_elems = int(len(docs_Sets) * (len(docs_Sets) - 1) / 2)\n",
    "    similarity_matrix = [0 for x in range(num_elems)]\n",
    "    for i in range(len(docs_Sets)):\n",
    "        for j in range(i + 1, len(docs_Sets)):\n",
    "            similarity_matrix[get_triangle_index(i, j, len(docs_Sets))] = jaccard(\n",
    "                docs_Sets[i], docs_Sets[j])\n",
    "\n",
    "    return similarity_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stuff to do before running own methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reading...\n",
      "5 documents were read in 0.0018680095672607422 sec\n",
      "\n",
      "Starting to calculate the similarities of documents...\n",
      "Calculating the similarities of 10 combinations of documents took 0.0 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Global parameters\n",
    "parameter_file = 'default_parameters.ini'  # the main parameters file\n",
    "# the main path where all the data directories are\n",
    "data_main_directory = Path('data')\n",
    "# dictionary that holds the input parameters, key = parameter name, value = value\n",
    "parameters_dictionary = dict()\n",
    "# dictionary of the input documents, key = document id, value = the document\n",
    "document_list = dict()\n",
    "\n",
    "read_parameters()\n",
    "#print(parameters_dictionary['data'])\n",
    "\n",
    "# Reading the data\n",
    "print(\"Data reading...\")\n",
    "data_folder = data_main_directory / parameters_dictionary['data']\n",
    "t0 = time.time()\n",
    "read_data(data_folder)\n",
    "document_list = {k: document_list[k] for k in sorted(document_list)}\n",
    "t1 = time.time()\n",
    "print(len(document_list), \"documents were read in\", t1 - t0, \"sec\\n\")\n",
    "\n",
    "# Naive\n",
    "naive_similarity_matrix = []\n",
    "if parameters_dictionary['naive']:\n",
    "    print(\"Starting to calculate the similarities of documents...\")\n",
    "    t2 = time.time()\n",
    "    naive_similarity_matrix = naive()\n",
    "    t3 = time.time()\n",
    "    print(\"Calculating the similarities of\", len(naive_similarity_matrix),\n",
    "            \"combinations of documents took\", t3 - t2, \"sec\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods that we have to implement\n",
    "\n",
    "- [x] K-shingles\n",
    "- [ ] Signature sets\n",
    "- [ ] Min hash\n",
    "- [ ] LSH\n",
    "- [ ] Candidate similarities\n",
    "- [ ] Return results\n",
    "- [ ] Count false neg and pos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notater:\n",
    "\n",
    "k shingles: gjøre på nytt (fikse)\n",
    "            finner set med k-ord/karakterer i alle dokument og legger til i k-shingles\n",
    "\n",
    "signature matrix:   lager liste med hash verider som representerer kshingles fra i dokumentene\n",
    "                    legge til hashing\n",
    "\n",
    "min hash            a b p = primtall kanskje funker\n",
    "\n",
    "lsh forklaring av maggy og pp\n",
    "\n",
    "fortsettelse kommer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD FOR TASK 1\n",
    "# Creates the k-Shingles of each document and returns a list of them\n",
    "def k_shingles():\n",
    "    docs_k_shingles = set()  # holds the k-shingles of each document\n",
    "    # implement your code here\n",
    "\n",
    "    # Get the value k from the parameters dictionary\n",
    "    k = parameters_dictionary.get(\"k\")\n",
    "\n",
    "    # Iterate through the documents in document list\n",
    "    for key in document_list:\n",
    "        \n",
    "        document = document_list[key]\n",
    "        words = document.split()\n",
    "\n",
    "        for index in range(len(document) - k + 1):\n",
    "            shingle = words[index:index + k]\n",
    "            shingle = ' '.join(shingle)\n",
    "\n",
    "            if shingle not in docs_k_shingles:\n",
    "                docs_k_shingles.add(shingle)\n",
    "            else:\n",
    "                del shingle\n",
    "                index -= 1\n",
    "    return list(docs_k_shingles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_shingles2():\n",
    "    l = []\n",
    "    docs_k_shingles = []  # holds the k-shingles of each document\n",
    "    # implement your code here\n",
    "\n",
    "    # Get the value k from the parameters dictionary\n",
    "    k = parameters_dictionary.get(\"k\")\n",
    "\n",
    "    for key in document_list:\n",
    "        document = document_list[key]\n",
    "        words = document.split()\n",
    "        \n",
    "        #print(words)\n",
    "        #print(len(words))\n",
    "        shingles_in_doc = []\n",
    "        for i in range(len(words)-k+1):\n",
    "            #print(words[i])\n",
    "            \n",
    "            shingle = words[i:i + k]\n",
    "            #shingle = ' '.join(shingle)\n",
    "            \n",
    "            #print(shingle)\n",
    "            shingle = ' '.join(shingle)\n",
    "            #print(\"shingle: \",shingle)\n",
    "\n",
    "            #print(shingle not in docs_k_shingles)\n",
    "            #shingles_in_doc.append(shingle)\n",
    "            \n",
    "            if shingle not in shingles_in_doc:\n",
    "                #print(shingle not in docs_k_shingles)\n",
    "                shingles_in_doc.append(shingle)\n",
    "\n",
    "            #print(shingles_in_doc) \n",
    "        #print(len(shingles_in_doc))\n",
    "        docs_k_shingles.append(shingles_in_doc)\n",
    "\n",
    "        #print(\"\\n\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "    return docs_k_shingles\n",
    "\n",
    "docs_k_shingles = k_shingles2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "[['the cat plays with the', 'cat plays with the dog'], ['the dog plays with the', 'dog plays with the cat'], ['the boy plays with the', 'boy plays with the dog'], ['the cat eats a fish'], ['the dog eats a bone']]\n"
     ]
    }
   ],
   "source": [
    "print(len((docs_k_shingles[0][0])))\n",
    "print((docs_k_shingles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['the', 'cat', 'plays', 'with', 'the'], ['cat', 'plays', 'with', 'the', 'dog']], [['the', 'dog', 'plays', 'with', 'the'], ['dog', 'plays', 'with', 'the', 'cat']], [['the', 'boy', 'plays', 'with', 'the'], ['boy', 'plays', 'with', 'the', 'dog']], [['the', 'cat', 'eats', 'a', 'fish']], [['the', 'dog', 'eats', 'a', 'bone']]]\n"
     ]
    }
   ],
   "source": [
    "sh = k_shingles2()\n",
    "#print(type(sh))\n",
    "print(sh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with the dog\n"
     ]
    }
   ],
   "source": [
    "#for i in range(1000):\n",
    "i = 1\n",
    "print(sh[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the document matrix\n",
    "def make_document_matrix(document_collection, k_shingles_set):\n",
    "    # Make a list of zeroes of length equal to the number of shingles\n",
    "    all_zeroes_vector = [0 for _ in k_shingles_set]\n",
    "\n",
    "    doc_matrix = pd.DataFrame({'d1': all_zeroes_vector,\n",
    "                               'd2': all_zeroes_vector,\n",
    "                               'd3': all_zeroes_vector,\n",
    "                               'd4': all_zeroes_vector,\n",
    "                               'd5': all_zeroes_vector,\n",
    "                               'd6': all_zeroes_vector,\n",
    "                               'd7': all_zeroes_vector,\n",
    "                               'd8': all_zeroes_vector,\n",
    "                               'd9': all_zeroes_vector,\n",
    "                               'd10': all_zeroes_vector,\n",
    "                               'shingle': [f\"'{i}'\" for i in k_shingles_set]})\n",
    "\n",
    "    for shingle_index, shingle in enumerate(k_shingles_set):\n",
    "        print(\"shingle index: \", type(shingle_index), \"   shingle: \", type(shingle))\n",
    "\n",
    "        for doc_index, doc in enumerate(document_collection):\n",
    "            if shingle in doc:\n",
    "                doc_matrix.iloc[shingle_index, doc_index] = 1\n",
    "\n",
    "    return doc_matrix\n",
    "\n",
    "\n",
    "# Make the document matrix for the documents\n",
    "#document_matrix = make_document_matrix(document_list, sh)\n",
    "\n",
    "# Display the document matrix\n",
    "#display(document_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD FOR TASK 2\n",
    "# Creates a signatures set of the documents from the k-shingles list\n",
    "def signature_set(k_shingles):\n",
    "    docs_sig_sets = []\n",
    "\n",
    "    for key in document_list:\n",
    "        document = document_list[key]\n",
    "        document_signature = []\n",
    "        for shingle in k_shingles:\n",
    "            if shingle in document:\n",
    "                document_signature.append(1)\n",
    "            else:\n",
    "                document_signature.append(0)\n",
    "        docs_sig_sets.append(document_signature)\n",
    "    return docs_sig_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the cat plays with the', 'cat plays with the dog'], ['the dog plays with the', 'dog plays with the cat'], ['the boy plays with the', 'boy plays with the dog'], ['the cat eats a fish'], ['the dog eats a bone']]\n",
      "key  0\n",
      "doc:  the cat plays with the dog\n",
      "the cat plays with the\n",
      "cat plays with the dog\n",
      "\n",
      "key  1\n",
      "doc:  the dog plays with the cat\n",
      "the dog plays with the\n",
      "dog plays with the cat\n",
      "\n",
      "key  2\n",
      "doc:  the boy plays with the dog\n",
      "the boy plays with the\n",
      "boy plays with the dog\n",
      "\n",
      "key  3\n",
      "doc:  the cat eats a fish\n",
      "the cat eats a fish\n",
      "\n",
      "key  4\n",
      "doc:  the dog eats a bone\n",
      "the dog eats a bone\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "signature matrix:   \n",
    "    lager liste med hash verider som representerer kshingles fra i dokumentene\n",
    "    legge til hashing\n",
    "\n",
    "\"\"\"\n",
    "# METHOD FOR TASK 2\n",
    "# Creates a signatures set of the documents from the k-shingles list\n",
    "def signature_set_lang(shingles):\n",
    "    #docs_sig_sets = []\n",
    "    print(shingles)\n",
    "\n",
    "    for key in range(len(document_list)):\n",
    "        print(\"key \", key)\n",
    "        #print(document_list[key])\n",
    "        #print(len(document_list))\n",
    "\n",
    "\n",
    "\n",
    "        #print(type(document_list))\n",
    "        \n",
    "        #for shingle in document_list\n",
    "        document = document_list[key+1]\n",
    "        print(\"doc: \",document)\n",
    "        for i in range(len(shingles[key])):\n",
    "            print(shingles[key][i])\n",
    "       \n",
    "        #for index in range(len(k_shingles_input)):\n",
    "            #print(\"shingles\", k_shingles_input[key-1])\n",
    "        print(\"\")\n",
    "       \n",
    "    #return docs_sig_sets\n",
    "\n",
    "signature_set = signature_set_lang(docs_k_shingles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sig = signature_set_lang(sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(sig[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_prime(n):\n",
    "  if n == 2 or n == 3: return True\n",
    "  if n < 2 or n%2 == 0: return False\n",
    "  if n < 9: return True\n",
    "  if n%3 == 0: return False\n",
    "  r = int(n**0.5)\n",
    "  # since all primes > 3 are of the form 6n ± 1\n",
    "  # start with f=5 (which is prime)\n",
    "  # and test f, f+2 for being prime\n",
    "  # then loop by 6. \n",
    "  f = 5\n",
    "  while f <= r:\n",
    "    if n % f == 0: return False\n",
    "    if n % (f+2) == 0: return False\n",
    "    f += 6\n",
    "  return True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD FOR TASK 3\n",
    "# Creates the minHash signatures after simulation of permutations\n",
    "random.seed(11)\n",
    "\n",
    "def minHash(document_vector):\n",
    "    signature = []\n",
    "\n",
    "    number_of_hashes = parameters_dictionary.get(\"permutations\")\n",
    "    \n",
    "    # Generate random permutations\n",
    "    permutations = []\n",
    "    for i in range(number_of_hashes):\n",
    "        permutation = list(range(len(document_vector)))\n",
    "        random.shuffle(permutation)\n",
    "        permutations.append(permutation)\n",
    "\n",
    "    # Make the minhash signature\n",
    "    for i in range(number_of_hashes):\n",
    "        hash_values = []\n",
    "        for permutation_value_pair in zip(permutations[i], document_vector):\n",
    "            p, v = permutation_value_pair\n",
    "            if v == 1:\n",
    "                hash_values.append(p)\n",
    "        signature.append(min(hash_values))\n",
    "\n",
    "    return signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New minhash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "minhash_signature_matrix = []\n",
    "for i in range(len(sig)):\n",
    "    minhash_signature_matrix.append(minHash(sig[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(len(minhash_signature_matrix))\n",
    "print(sig[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD FOR TASK 4\n",
    "# Hashes the MinHash Signature Matrix into buckets and find candidate similar documents\n",
    "def lsh(m_matrix):\n",
    "    candidates = []  # list of candidate sets of documents for checking similarity\n",
    "\n",
    "    # implement your code here\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD FOR TASK 4\n",
    "# Hashes the MinHash Signature Matrix into buckets and find candidate similar documents\n",
    "def lsh(m_matrix):\n",
    "    candidates = []  # list of candidate sets of documents for checking similarity\n",
    "\n",
    "    \"\"\" \n",
    "    candidate pairs av dokumenter muligens like\n",
    "    bruk rader r og bøtter buckets som inndata parametre \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # implement your code here\n",
    "    r = parameters_dictionary.get(\"r\")\n",
    "    buckets = parameters_dictionary.get(\"buckets\")\n",
    "    \n",
    "\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
