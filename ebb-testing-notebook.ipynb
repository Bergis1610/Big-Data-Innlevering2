{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook for testing purposes\n",
    "\n",
    "##### Imports and global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser  # for reading the parameters file\n",
    "import sys  # for system errors and printouts\n",
    "from pathlib import Path  # for paths of files\n",
    "import os  # for reading the input data\n",
    "import time  # for timing\n",
    "import pandas as pd\n",
    "import random \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "parameter_file = 'default_parameters.ini'  # the main parameters file\n",
    "# the main path where all the data directories are\n",
    "data_main_directory = Path('data')\n",
    "# dictionary that holds the input parameters, key = parameter name, value = value\n",
    "parameters_dictionary = dict()\n",
    "# dictionary of the input documents, key = document id, value = the document\n",
    "document_list = dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-implemented methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DO NOT CHANGE THIS METHOD\n",
    "# Reads the parameters of the project from the parameter file 'file'\n",
    "# and stores them to the parameter dictionary 'parameters_dictionary'\n",
    "def read_parameters():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(parameter_file)\n",
    "    for section in config.sections():\n",
    "        for key in config[section]:\n",
    "            if key == 'data':\n",
    "                parameters_dictionary[key] = config[section][key]\n",
    "            elif key == 'naive':\n",
    "                parameters_dictionary[key] = bool(config[section][key])\n",
    "            elif key == 't':\n",
    "                parameters_dictionary[key] = float(config[section][key])\n",
    "            else:\n",
    "                parameters_dictionary[key] = int(config[section][key])\n",
    "\n",
    "\n",
    "# DO NOT CHANGE THIS METHOD\n",
    "# Reads all the documents in the 'data_path' and stores them in the dictionary 'document_list'\n",
    "def read_data(data_path):\n",
    "    for (root, dirs, file) in os.walk(data_path):\n",
    "        for f in file:\n",
    "            file_path = data_path / f\n",
    "            doc = open(file_path).read().strip().replace('\\n', ' ')\n",
    "            file_id = int(file_path.stem)\n",
    "            document_list[file_id] = doc\n",
    "\n",
    "\n",
    "# DO NOT CHANGE THIS METHOD\n",
    "# Calculates the Jaccard Similarity between two documents represented as sets\n",
    "def jaccard(doc1, doc2):\n",
    "    return len(doc1.intersection(doc2)) / float(len(doc1.union(doc2)))\n",
    "\n",
    "\n",
    "# DO NOT CHANGE THIS METHOD\n",
    "# Define a function to map a 2D matrix coordinate into a 1D index.\n",
    "def get_triangle_index(i, j, length):\n",
    "    if i == j:  # that's an error.\n",
    "        sys.stderr.write(\"Can't access triangle matrix with i == j\")\n",
    "        sys.exit(1)\n",
    "    if j < i:  # just swap the values.\n",
    "        temp = i\n",
    "        i = j\n",
    "        j = temp\n",
    "\n",
    "    # Calculate the index within the triangular array. Taken from pg. 211 of:\n",
    "    # http://infolab.stanford.edu/~ullman/mmds/ch6.pdf\n",
    "    # adapted for a 0-based index.\n",
    "    k = int(i * (length - (i + 1) / 2.0) + j - i) - 1\n",
    "\n",
    "    return k\n",
    "\n",
    "\n",
    "# DO NOT CHANGE THIS METHOD\n",
    "# Calculates the similarities of all the combinations of documents and returns the similarity triangular matrix\n",
    "def naive():\n",
    "    docs_Sets = []  # holds the set of words of each document\n",
    "\n",
    "    for doc in document_list.values():\n",
    "        docs_Sets.append(set(doc.split()))\n",
    "\n",
    "    # Using triangular array to store the similarities, avoiding half size and similarities of i==j\n",
    "    num_elems = int(len(docs_Sets) * (len(docs_Sets) - 1) / 2)\n",
    "    similarity_matrix = [0 for x in range(num_elems)]\n",
    "    for i in range(len(docs_Sets)):\n",
    "        for j in range(i + 1, len(docs_Sets)):\n",
    "            similarity_matrix[get_triangle_index(i, j, len(docs_Sets))] = jaccard(\n",
    "                docs_Sets[i], docs_Sets[j])\n",
    "\n",
    "    return similarity_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stuff to do before running own methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reading...\n",
      "5 documents were read in 0.03299593925476074 sec\n",
      "\n",
      "Starting to calculate the similarities of documents...\n",
      "Calculating the similarities of 10 combinations of documents took 0.0 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Global parameters\n",
    "parameter_file = 'default_parameters.ini'  # the main parameters file\n",
    "# the main path where all the data directories are\n",
    "data_main_directory = Path('data')\n",
    "# dictionary that holds the input parameters, key = parameter name, value = value\n",
    "parameters_dictionary = dict()\n",
    "# dictionary of the input documents, key = document id, value = the document\n",
    "document_list = dict()\n",
    "\n",
    "read_parameters()\n",
    "#print(parameters_dictionary['data'])\n",
    "\n",
    "# Reading the data\n",
    "print(\"Data reading...\")\n",
    "data_folder = data_main_directory / parameters_dictionary['data']\n",
    "t0 = time.time()\n",
    "read_data(data_folder)\n",
    "document_list = {k: document_list[k] for k in sorted(document_list)}\n",
    "t1 = time.time()\n",
    "print(len(document_list), \"documents were read in\", t1 - t0, \"sec\\n\")\n",
    "\n",
    "# Naive\n",
    "naive_similarity_matrix = []\n",
    "if parameters_dictionary['naive']:\n",
    "    print(\"Starting to calculate the similarities of documents...\")\n",
    "    t2 = time.time()\n",
    "    naive_similarity_matrix = naive()\n",
    "    t3 = time.time()\n",
    "    print(\"Calculating the similarities of\", len(naive_similarity_matrix),\n",
    "            \"combinations of documents took\", t3 - t2, \"sec\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods that we have to implement\n",
    "\n",
    "- [x] K-shingles\n",
    "- [ ] Signature sets\n",
    "- [ ] Min hash\n",
    "- [ ] LSH\n",
    "- [ ] Candidate similarities\n",
    "- [ ] Return results\n",
    "- [ ] Count false neg and pos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notater:\n",
    "\n",
    "k shingles: gjøre på nytt (fikse)\n",
    "            finner set med k-ord/karakterer i alle dokument og legger til i k-shingles\n",
    "\n",
    "signature matrix:   lager liste med hash verider som representerer kshingles fra i dokumentene\n",
    "                    legge til hashing\n",
    "\n",
    "min hash            a b p = primtall kanskje funker\n",
    "\n",
    "lsh forklaring av maggy og pp\n",
    "\n",
    "fortsettelse kommer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD FOR TASK 1\n",
    "# Creates the k-Shingles of each document and returns a list of them\n",
    "def k_shingles_test():\n",
    "    docs_k_shingles = set()  # holds the k-shingles of each document\n",
    "    # implement your code here\n",
    "\n",
    "    # Get the value k from the parameters dictionary\n",
    "    k = parameters_dictionary.get(\"k\")\n",
    "\n",
    "    # Iterate through the documents in document list\n",
    "    for key in document_list:\n",
    "        \n",
    "        document = document_list[key]\n",
    "        words = document.split()\n",
    "\n",
    "        for index in range(len(document) - k + 1):\n",
    "            shingle = words[index:index + k]\n",
    "            shingle = ' '.join(shingle)\n",
    "\n",
    "            if shingle not in docs_k_shingles:\n",
    "                docs_k_shingles.add(shingle)\n",
    "            else:\n",
    "                del shingle\n",
    "                index -= 1\n",
    "    return list(docs_k_shingles)\n",
    "\n",
    "ett_eller_annet = k_shingles_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ett_eller_annet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_shingles():\n",
    "    docs_k_shingles = []  # holds the k-shingles of each document\n",
    "    # implement your code here\n",
    "\n",
    "    # Get the value k from the parameters dictionary\n",
    "    k = parameters_dictionary.get(\"k\")\n",
    "\n",
    "    for key in document_list:\n",
    "        document = document_list[key]\n",
    "        words = document.split()\n",
    "        \n",
    "        #print(words)\n",
    "        #print(len(words))\n",
    "        shingles_in_doc = []\n",
    "        for i in range(len(words)-k+1):\n",
    "            #print(words[i])\n",
    "            \n",
    "            shingle = words[i:i + k]\n",
    "            #shingle = ' '.join(shingle)\n",
    "            \n",
    "            #print(shingle)\n",
    "            shingle = ' '.join(shingle)\n",
    "            #print(\"shingle: \",shingle)\n",
    "\n",
    "            #print(shingle not in docs_k_shingles)\n",
    "            #shingles_in_doc.append(shingle)\n",
    "            \n",
    "            if shingle not in shingles_in_doc:\n",
    "                #print(shingle not in docs_k_shingles)\n",
    "                shingles_in_doc.append(shingle)\n",
    "\n",
    "            #print(shingles_in_doc) \n",
    "        #print(len(shingles_in_doc))\n",
    "        docs_k_shingles.append(shingles_in_doc)\n",
    "\n",
    "        #print(\"\\n\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "    return docs_k_shingles\n",
    "\n",
    "docs_k_shingles = k_shingles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "[['the cat plays with the', 'cat plays with the dog'], ['the dog plays with the', 'dog plays with the cat'], ['the boy plays with the', 'boy plays with the dog'], ['the cat eats a fish'], ['the dog eats a bone']]\n"
     ]
    }
   ],
   "source": [
    "print(len((docs_k_shingles[0][0])))\n",
    "print((docs_k_shingles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = k_shingles()\n",
    "#print(type(sh))\n",
    "print(sh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(1000):\n",
    "i = 1\n",
    "print(sh[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the document matrix\n",
    "def make_document_matrix(document_collection, k_shingles_set):\n",
    "    # Make a list of zeroes of length equal to the number of shingles\n",
    "    all_zeroes_vector = [0 for _ in k_shingles_set]\n",
    "\n",
    "    doc_matrix = pd.DataFrame({'d1': all_zeroes_vector,\n",
    "                               'd2': all_zeroes_vector,\n",
    "                               'd3': all_zeroes_vector,\n",
    "                               'd4': all_zeroes_vector,\n",
    "                               'd5': all_zeroes_vector,\n",
    "                               'd6': all_zeroes_vector,\n",
    "                               'd7': all_zeroes_vector,\n",
    "                               'd8': all_zeroes_vector,\n",
    "                               'd9': all_zeroes_vector,\n",
    "                               'd10': all_zeroes_vector,\n",
    "                               'shingle': [f\"'{i}'\" for i in k_shingles_set]})\n",
    "\n",
    "    for shingle_index, shingle in enumerate(k_shingles_set):\n",
    "        print(\"shingle index: \", type(shingle_index), \"   shingle: \", type(shingle))\n",
    "\n",
    "        for doc_index, doc in enumerate(document_collection):\n",
    "            if shingle in doc:\n",
    "                doc_matrix.iloc[shingle_index, doc_index] = 1\n",
    "\n",
    "    return doc_matrix\n",
    "\n",
    "\n",
    "# Make the document matrix for the documents\n",
    "#document_matrix = make_document_matrix(document_list, sh)\n",
    "\n",
    "# Display the document matrix\n",
    "#display(document_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD FOR TASK 2\n",
    "# Creates a signatures set of the documents from the k-shingles list\n",
    "def signature_set_feil(k_shingles):\n",
    "    docs_sig_sets = []\n",
    "\n",
    "    for key in range(0,len(document_list)):\n",
    "        document = document_list[key+1]\n",
    "        #print(document)\n",
    "        document_signature = []\n",
    "        for shingle in k_shingles[key]:\n",
    "            #print(\"shingle\", shingle)\n",
    "            if shingle in document:\n",
    "                document_signature.append(1)\n",
    "            else:\n",
    "                document_signature.append(0)\n",
    "        docs_sig_sets.append(document_signature)\n",
    "    return docs_sig_sets\n",
    "\n",
    "feil_sigs = signature_set_feil(docs_k_shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(feil_sigs[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len 5\n",
      "key  0\n",
      "shingle ['the cat plays with the', 'cat plays with the dog']\n",
      "-8309069388399050952\n",
      "-4400295948781053574\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "key  1\n",
      "shingle ['the dog plays with the', 'dog plays with the cat']\n",
      "-7037144528784916997\n",
      "-1026798105466631651\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "key  2\n",
      "shingle ['the boy plays with the', 'boy plays with the dog']\n",
      "7745935074081176009\n",
      "-8256888659976630353\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "key  3\n",
      "shingle ['the cat eats a fish']\n",
      "-3803182783533912961\n",
      "{-3803182783533912961}\n",
      "key  4\n",
      "shingle ['the dog eats a bone']\n",
      "7976188737135935259\n",
      "{7976188737135935259}\n"
     ]
    }
   ],
   "source": [
    "# METHOD FOR TASK 2\n",
    "# Creates a signatures set of the documents from the k-shingles list\n",
    "def signature_set(shingles):\n",
    "    #docs_sig_sets = []\n",
    "    #print(shingles)\n",
    "    \n",
    "    docs_signature_sets = []\n",
    "    print(\"len\",len(document_list))\n",
    "    for key in range(0, len(document_list)):\n",
    "        print(\"key \", key)\n",
    "        #print(document_list[key])\n",
    "        #print(len(document_list))\n",
    "\n",
    "        shingle = shingles[key]\n",
    "        print(\"shingle\",shingle)\n",
    "        signature_set_shingle  = set()\n",
    "\n",
    "        #print(type(document_list))\n",
    "        \n",
    "        #for shingle in document_list\n",
    "        #document = document_list[key+1]\n",
    "\n",
    "        #print(\"doc: \",document)\n",
    "        for i in range(len(shingles[key])):\n",
    "            hash_val = hash(shingle[i])\n",
    "            print(hash_val)\n",
    "            if hash_val not in signature_set_shingle:\n",
    "                signature_set_shingle.add(hash_val)\n",
    "\n",
    "            #shing = shingles[key][i]\n",
    "            #print(shing in document)\n",
    "        print(signature_set_shingle)\n",
    "        docs_signature_sets.append(signature_set_shingle)\n",
    "    return docs_signature_sets\n",
    "        #for index in range(len(k_shingles_input)):\n",
    "            #print(\"shingles\", k_shingles_input[key-1])\n",
    "        #print(\"\")\n",
    "       \n",
    "    #return docs_sig_sets\n",
    "\n",
    "sig_set = signature_set(docs_k_shingles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(sig_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_prime(n):\n",
    "  if n == 2 or n == 3: return True\n",
    "  if n < 2 or n%2 == 0: return False\n",
    "  if n < 9: return True\n",
    "  if n%3 == 0: return False\n",
    "  r = int(n**0.5)\n",
    "  # since all primes > 3 are of the form 6n ± 1\n",
    "  # start with f=5 (which is prime)\n",
    "  # and test f, f+2 for being prime\n",
    "  # then loop by 6. \n",
    "  f = 5\n",
    "  while f <= r:\n",
    "    if n % f == 0: return False\n",
    "    if n % (f+2) == 0: return False\n",
    "    f += 6\n",
    "  return True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perms  10\n",
      "docs  5\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "{-3803182783533912961}\n",
      "{7976188737135935259}\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "{-3803182783533912961}\n",
      "{7976188737135935259}\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "{-3803182783533912961}\n",
      "{7976188737135935259}\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "{-3803182783533912961}\n",
      "{7976188737135935259}\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "{-3803182783533912961}\n",
      "{7976188737135935259}\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "{-3803182783533912961}\n",
      "{7976188737135935259}\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "{-3803182783533912961}\n",
      "{7976188737135935259}\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "{-3803182783533912961}\n",
      "{7976188737135935259}\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "{-3803182783533912961}\n",
      "{7976188737135935259}\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "{-4400295948781053574, -8309069388399050952}\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "{-7037144528784916997, -1026798105466631651}\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "{-8256888659976630353, 7745935074081176009}\n",
      "{-3803182783533912961}\n",
      "{7976188737135935259}\n",
      "perm count  10 \n",
      "docies count  50 \n",
      "total count  80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nOutput burde være en matrise med dimensjoner permutasjoner x filer\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# METHOD FOR TASK 3\n",
    "# Creates the minHash signatures after simulation of permutations\n",
    "def minHash(sig_set):\n",
    "    \n",
    "\n",
    "    #print(\"a \", a, \" b \", b, \" p \", p)\n",
    "\n",
    "\n",
    "    num_permutations = parameters_dictionary.get(\"permutations\")\n",
    "    print(\"perms \", num_permutations)\n",
    "    num_documents = len(document_list)\n",
    "    print(\"docs \", num_documents)\n",
    "    num_shingles = len(docs_k_shingles)\n",
    "\n",
    "    signatures = np.full((num_permutations, num_documents), np.inf)\n",
    "    count = 0\n",
    "    perms = 0\n",
    "    docies = 0\n",
    "    for i in range(num_permutations):\n",
    "        a = random.randint(1, 400)\n",
    "        b = random.randint(1, 400)\n",
    "        cont = True\n",
    "        while cont:\n",
    "            # Generate a random number in the range [lower_bound, upper_bound]\n",
    "            p = random.randint(30,100)\n",
    "            \n",
    "            # Check if the number is prime\n",
    "            if is_prime(p):\n",
    "                cont = False\n",
    "        perms += 1\n",
    "        #print(\"i \",i)\n",
    "        for j in range(num_documents):\n",
    "            docies +=1\n",
    "            # print(\" j \", j)\n",
    "            localcount = 1\n",
    "            for sig in sig_set[j]:\n",
    "                print(sig_set[j])\n",
    "                \n",
    "                #print(\"sig \", sig)\n",
    "\n",
    "                hash_value = (a * sig + b) % p\n",
    "                #print(\"hash \",hash_value)\n",
    "                #print(localcount)\n",
    "                count+=1\n",
    "                localcount +=1\n",
    "\n",
    "                #print(\"i and j: \", i,\",\", j)\n",
    "\n",
    "                if hash_value < signatures[i][j]:\n",
    "                    signatures[i][j] = hash_value\n",
    "                #print(signatures)\n",
    "            #print(signatures)\n",
    "    print(\"perm count \",perms, \"\\ndocies count \", docies, \"\\ntotal count \", count)\n",
    "\n",
    "    return signatures\n",
    "    \n",
    "\n",
    "\n",
    "minihash = minHash(sig_set)\n",
    "\n",
    "\"\"\"\n",
    "Output burde være en matrise med dimensjoner permutasjoner x filer\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54. 17. 18. 33. 21.]\n",
      " [34.  2.  7. 38. 38.]\n",
      " [ 8. 17. 31. 25. 43.]\n",
      " [ 7.  5. 10. 22. 57.]\n",
      " [ 3. 32.  7. 35. 11.]\n",
      " [50. 35. 26. 53. 12.]\n",
      " [26.  1. 15.  9. 12.]\n",
      " [14. 27. 17. 34. 23.]\n",
      " [30. 12. 38.  6. 39.]\n",
      " [12.  5. 20. 31.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(minihash)\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD FOR TASK 4\n",
    "# Hashes the MinHash Signature Matrix into buckets and find candidate similar documents\n",
    "def lsh(m_matrix):\n",
    "    candidates = []  # list of candidate sets of documents for checking similarity\n",
    "\n",
    "    # implement your code here\n",
    "\n",
    "    return candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD FOR TASK 3\n",
    "# Creates the minHash signatures after simulation of permutations\n",
    "random.seed(11)\n",
    "\n",
    "#input = signature_set\n",
    "def minHash_gammel(sig_set):\n",
    "    #print(\"sigs \" ,sig_set)\n",
    "    signature = []\n",
    "\n",
    "    number_of_hashes = parameters_dictionary.get(\"permutations\")\n",
    "    \n",
    "    # Generate random permutations\n",
    "    permutations = []\n",
    "    for i in range(number_of_hashes):\n",
    "        permutation = list(range(len(sig_set)))\n",
    "        random.shuffle(permutation)\n",
    "        permutations.append(permutation)\n",
    "    print(permutations)\n",
    "\n",
    "    # Make the minhash signature\n",
    "    for i in range(number_of_hashes):\n",
    "        hash_values = []\n",
    "\n",
    "        for permutation_value_pair in zip(permutations[i], sig_set):\n",
    "            p, v = permutation_value_pair\n",
    "            print(\"p \",p, \" v \", v )\n",
    "            if v == 1:\n",
    "                hash_values.append(p)\n",
    "                print(\"true\")\n",
    "            else: print(\"false\")\n",
    "        print(hash_values)\n",
    "        signature.append(min(hash_values))\n",
    "\n",
    "    return signature\n",
    "\n",
    "gammel_minihash = minHash_gammel(feil_sigs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####KLADDD\n",
    "def signature_set_gammel(k_shingles):\n",
    "    docs_sig_sets = []\n",
    "\n",
    "    for key in document_list:\n",
    "        document = document_list[key]\n",
    "        document_signature = []\n",
    "        for shingle in k_shingles:\n",
    "            if shingle in document:\n",
    "                document_signature.append(1)\n",
    "            else:\n",
    "                document_signature.append(0)\n",
    "        docs_sig_sets.append(document_signature)\n",
    "    return docs_sig_sets\n",
    "\n",
    "    docs_sig_sets = []\n",
    "\n",
    "    all_zeroes_vector = [0 for _ in k_shingles]\n",
    "    document_matrix = pd.DataFrame([])\n",
    "\n",
    "    all_documents = []\n",
    "    for key in document_list:\n",
    "        all_documents.append(all_zeroes_vector)\n",
    "    documents_df = pd.DataFrame(all_documents)\n",
    "\n",
    "    for shingle_index, shingle in enumerate(k_shingles):\n",
    "        for doc_index, doc in enumerate(document_list):\n",
    "            if shingle in doc:\n",
    "                documents_df.iloc[shingle_index, doc_index] = 1\n",
    "\n",
    "    return document_matrix\n",
    "\n",
    "   # Check if each k-shingle is in the set for each document\n",
    "    for k_shingle in k_shingles:\n",
    "        document_signature = []\n",
    "        for k_shingles_set in doc_k_shingles:\n",
    "            if k_shingle in k_shingles_set:\n",
    "                document_signature.append(1)\n",
    "            else:\n",
    "                document_signature.append(0)\n",
    "        docs_sig_sets.append(document_signature)\n",
    "\n",
    "    return docs_sig_sets\n",
    "\n",
    "    docs_sig_sets = []\n",
    "    # Create a set of all k-shingles for each document\n",
    "    doc_k_shingles = []\n",
    "    k = parameters_dictionary.get(\"k\")\n",
    "    for key in document_list:\n",
    "        document = document_list[key]\n",
    "        k_shingles_set = set()\n",
    "        for i in range(len(document) - k + 1):\n",
    "            k_shingle = document[i:i+k]\n",
    "            k_shingles_set.add(k_shingle)\n",
    "        doc_k_shingles.append(k_shingles_set)\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    docs_sig_sets = []\n",
    "    # implement your code here\n",
    "    i = 0\n",
    "\n",
    "    for document in document_list.values():\n",
    "        doc_k_shingles = set(document.split())\n",
    "        document_signature = [\n",
    "            1 if shingle in doc_k_shingles else 0 for shingle in k_shingles]\n",
    "        docs_sig_sets.append(document_signature)\n",
    "        while i < 1:\n",
    "            i += 1\n",
    "            print(docs_sig_sets)\n",
    "    return docs_sig_sets\n",
    "\n",
    "    k = parameters_dictionary.get(\"k\")\n",
    "    i = 0\n",
    "    for key in document_list:\n",
    "        document = document_list[key]\n",
    "        words = document.split()\n",
    "        document_signature = []\n",
    "        for index in range(len(document) - k + 1):\n",
    "            shingle = words[index:index + k]\n",
    "            shingle = ' '.join(shingle)\n",
    "            if shingle in k_shingles:\n",
    "                document_signature.append(1)\n",
    "            else:\n",
    "                document_signature.append(0)\n",
    "        # while i < 1:\n",
    "            # i += 1\n",
    "            # print(docs_sig_sets)\n",
    "    return docs_sig_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New minhash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD FOR TASK 4\n",
    "# Hashes the MinHash Signature Matrix into buckets and find candidate similar documents\n",
    "def lsh(m_matrix):\n",
    "    candidates = []  # list of candidate sets of documents for checking similarity\n",
    "\n",
    "    # implement your code here\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD FOR TASK 4\n",
    "# Hashes the MinHash Signature Matrix into buckets and find candidate similar documents\n",
    "def lsh(m_matrix):\n",
    "    candidates = []  # list of candidate sets of documents for checking similarity\n",
    "\n",
    "    \"\"\" \n",
    "    candidate pairs av dokumenter muligens like\n",
    "    bruk rader r og bøtter buckets som inndata parametre \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # implement your code here\n",
    "    r = parameters_dictionary.get(\"r\")\n",
    "    buckets = parameters_dictionary.get(\"buckets\")\n",
    "    \n",
    "\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
